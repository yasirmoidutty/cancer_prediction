{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbbc3250-f7dc-4731-be14-e56912a4c354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2  # OpenCV for image processing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.utils import resample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f66526fe-8e2f-4d72-8246-956169770a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the image size\n",
    "IMAGE_SIZE = (64, 64)  # Adjust as necessary\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Constants\n",
    "IMAGE_SIZE = (64, 64)  # Update to the desired size for resizing images\n",
    "\n",
    "def load_data(data_dir):\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for label in ['malignant', 'benign']:\n",
    "        folder_path = os.path.join(data_dir, label)\n",
    "        for filename in os.listdir(folder_path):\n",
    "            img_path = os.path.join(folder_path, filename)\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is not None:\n",
    "                img = cv2.resize(img, IMAGE_SIZE)\n",
    "                img = img.flatten()  # Flatten to 1D array\n",
    "                images.append(img)\n",
    "                labels.append(1 if label == 'malignant' else 0)  # 1 for malignant, 0 for benign\n",
    "\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    return images, labels\n",
    "\n",
    "\n",
    "# Load images and labels\n",
    "data_dir = r'C:\\Users\\sanji\\OneDrive\\Desktop\\abhi assi\\BreaKHis_Total_dataset'  # Update with your dataset path\n",
    "X, y = load_data(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6aad7303-fd1a-45db-a32e-9e325447f32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming X is your feature matrix and y is your target vector\n",
    "# Convert X and y to a DataFrame for easier manipulation\n",
    "data = pd.DataFrame(X)\n",
    "data['target'] = y\n",
    "\n",
    "# Separate data by class\n",
    "class_0 = data[data['target'] == 0]\n",
    "class_1 = data[data['target'] == 1]\n",
    "\n",
    "# Define the size of the test set for each class\n",
    "test_size_per_class = min(len(class_0), len(class_1)) // 5  # e.g., 20% of the smaller class\n",
    "m = int(0.1 * (len(class_0) + len(class_1)))\n",
    "# Sample equal number of instances from each class for the test set\n",
    "test_0 = class_0.sample(n= m, random_state=42)\n",
    "test_1 = class_1.sample(n= m, random_state=42)\n",
    "\n",
    "# Combine the samples to form the test set\n",
    "test_data = pd.concat([test_0, test_1])\n",
    "\n",
    "# Drop the test instances from the original data to form the train set\n",
    "train_data = data.drop(test_data.index)\n",
    "\n",
    "# Separate features and target for train and test sets\n",
    "X_train = train_data.drop(columns='target')\n",
    "y_train = train_data['target']\n",
    "X_test = test_data.drop(columns='target')\n",
    "y_test = test_data['target']\n",
    "\n",
    "# Separate majority and minority classes in the training set\n",
    "malignant_images = X_train[y_train == 1]\n",
    "benign_images = X_train[y_train == 0]\n",
    "\n",
    "# Determine the number of samples to match classes in the training set\n",
    "n_samples = max(len(malignant_images), len(benign_images))\n",
    "\n",
    "# Resample minority class in the training set to match the majority class\n",
    "malignant_images_resampled = resample(\n",
    "    malignant_images, replace=True, n_samples=n_samples, random_state=42\n",
    ")\n",
    "benign_images_resampled = resample(\n",
    "    benign_images, replace=True, n_samples=n_samples, random_state=42\n",
    ")\n",
    "\n",
    "# Combine resampled images and labels for the training set\n",
    "X_train_balanced = np.vstack((malignant_images_resampled, benign_images_resampled))\n",
    "y_train_balanced = np.hstack((\n",
    "    np.ones(len(malignant_images_resampled)),\n",
    "    np.zeros(len(benign_images_resampled))\n",
    "))\n",
    "\n",
    "# Shuffle the balanced training set\n",
    "indices = np.arange(X_train_balanced.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "X_train_balanced = X_train_balanced[indices]\n",
    "y_train_balanced = y_train_balanced[indices]\n",
    "\n",
    "# The final training and testing sets\n",
    "X_train, y_train = X_train_balanced, y_train_balanced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9a7b786-c34d-4311-ad82-01f6904da442",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=5)\n",
    "\n",
    " # Fit PCA on the training features and transform both train and test sets\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)  # Only transform on test set\n",
    " # Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_pca)\n",
    "X_test_scaled = scaler.transform(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0118d495-39dd-4d65-89c7-554c70a1d90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.81      0.83       778\n",
      "           1       0.82      0.86      0.84       778\n",
      "\n",
      "    accuracy                           0.83      1556\n",
      "   macro avg       0.83      0.83      0.83      1556\n",
      "weighted avg       0.83      0.83      0.83      1556\n",
      "\n",
      "confusion matrix:\n",
      " [[627 151]\n",
      " [109 669]]\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine, after hyperparameter tuning\n",
    "svm_model = SVC(kernel='rbf', C=1.0,max_iter=10000, gamma='scale')\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "y_pred = svm_model.predict(X_test_scaled)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"confusion matrix:\\n\",confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d577ff93-0526-4916-8c3e-43353a782ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8354755784061697\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.80      0.83       778\n",
      "           1       0.81      0.87      0.84       778\n",
      "\n",
      "    accuracy                           0.84      1556\n",
      "   macro avg       0.84      0.84      0.84      1556\n",
      "weighted avg       0.84      0.84      0.84      1556\n",
      "\n",
      "Feature Importances: [0.20068307 0.4255214  0.10911647 0.18970275 0.07497631]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "# Initialize and train the model\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "rf_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Feature importance\n",
    "importances = rf_classifier.feature_importances_\n",
    "print(\"Feature Importances:\", importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7bff4db-fd02-4f2a-99b6-309be826b522",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=100)\n",
    "\n",
    " # Fit PCA on the training features and transform both train and test sets\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)  # Only transform on test set\n",
    " # Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_pca)\n",
    "X_test_scaled = scaler.transform(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e202dc2-1b9c-4f5a-be53-83abfff33575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.781491002570694\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.69      0.76       778\n",
      "           1       0.74      0.88      0.80       778\n",
      "\n",
      "    accuracy                           0.78      1556\n",
      "   macro avg       0.79      0.78      0.78      1556\n",
      "weighted avg       0.79      0.78      0.78      1556\n",
      "\n",
      "Feature Importances: [0.06960598 0.24494289 0.02523403 0.12250307 0.0085763  0.00765283\n",
      " 0.00653668 0.00594069 0.00472892 0.00572319 0.00536718 0.00717297\n",
      " 0.0050676  0.00431546 0.00447507 0.006577   0.00644891 0.00534798\n",
      " 0.00482633 0.00659712 0.00552294 0.00565997 0.00528607 0.00579762\n",
      " 0.00656071 0.00549012 0.00405657 0.0049937  0.00546873 0.00563109\n",
      " 0.00696395 0.00444805 0.00450713 0.00476362 0.00428044 0.00531696\n",
      " 0.00527993 0.0049596  0.00817602 0.00461288 0.00624581 0.00535857\n",
      " 0.00527879 0.00473282 0.0053972  0.0045435  0.00521697 0.00538399\n",
      " 0.00510754 0.00426865 0.00513883 0.00469178 0.00536866 0.00636153\n",
      " 0.00886379 0.0052085  0.00645566 0.00480568 0.00604762 0.00653159\n",
      " 0.00763033 0.00534766 0.00763281 0.00584725 0.00558497 0.0054484\n",
      " 0.00415053 0.0040151  0.00622796 0.00609285 0.00416788 0.00473004\n",
      " 0.00449455 0.0044229  0.00505446 0.00488158 0.00408029 0.00584656\n",
      " 0.00507848 0.00636827 0.0060355  0.00654831 0.00568089 0.00974092\n",
      " 0.00601263 0.00463318 0.00387379 0.00561797 0.00544105 0.0049014\n",
      " 0.00423645 0.00625652 0.00514906 0.00602153 0.00574619 0.00578087\n",
      " 0.00622597 0.00555144 0.00647237 0.00654733]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "# Initialize and train the model\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "rf_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Feature importance\n",
    "importances = rf_classifier.feature_importances_\n",
    "print(\"Feature Importances:\", importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b9f16a-599a-4c09-819c-b18327405bd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
